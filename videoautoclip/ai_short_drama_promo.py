#!/usr/bin/env python3
# ai_short_drama_promo.py
import os
import re
import argparse
import json
import logging
import requests
from typing import List, Callable, Optional
from datetime import timedelta

# å¯é€‰ï¼šä»…åœ¨éœ€è¦æ—¶å¯¼å…¥ moviepyï¼ˆé¿å…æ— å›¾å½¢ç¯å¢ƒæŠ¥é”™ï¼‰
try:
    from moviepy.editor import (
        VideoFileClip, concatenate_videoclips, CompositeVideoClip, AudioFileClip, afx
    )
    from moviepy.video.tools.subtitles import SubtitlesClip, TextClip
    MOVIEPY_AVAILABLE = True
except ImportError:
    MOVIEPY_AVAILABLE = False
    logging.warning("moviepy æœªå®‰è£…ï¼Œä»…æ”¯æŒå¯¼å‡ºå‰ªè¾‘æ—¶é—´æˆ³ï¼ˆæ— è§†é¢‘ç”Ÿæˆï¼‰")

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

FALLBACK_KEYWORDS = ["ä¸è¦", "ä¸¢ä¸‹", "å¯¹ä¸èµ·", "æ€€å­•", "ç™Œç—‡", "æ›¿èº«", "æ°¸è¿œ", "å†è§", "æ¨ä½ ", "çˆ±å¥¹"]

# ==================== SRT è§£æ ====================
def srt_to_segments(srt_path: str):
    with open(srt_path, 'r', encoding='utf-8') as f:
        content = f.read()
    # å¤„ç†ä¸åŒæ“ä½œç³»ç»Ÿçš„æ¢è¡Œç¬¦
    content = content.replace('\r\n', '\n').replace('\r', '\n')
    blocks = re.split(r'\n\s*\n', content.strip())
    segments = []
    full_text_parts = []
    for block in blocks:
        lines = [line.strip() for line in block.split('\n') if line.strip()]
        # è‡³å°‘éœ€è¦2è¡Œï¼ˆåºå·è¡Œå’Œæ—¶é—´è½´è¡Œï¼‰ï¼Œæ–‡æœ¬å¯ä»¥ä¸ºç©º
        if len(lines) < 2:
            continue
        try:
            # æ–‡æœ¬ä»ç¬¬3è¡Œå¼€å§‹ï¼Œå¦‚æœæ²¡æœ‰æ–‡æœ¬åˆ™ä¸ºç©ºå­—ç¬¦ä¸²
            text = ' '.join(lines[2:]) if len(lines) > 2 else ""
            full_text_parts.append(text)
            time_line = lines[1]
            start_str, end_str = time_line.split(' --> ')
            start_sec = time_str_to_seconds(start_str)
            end_sec = time_str_to_seconds(end_str)
            segments.append({'start': start_sec, 'end': end_sec, 'text': text})
        except Exception as e:
            # è®°å½•é”™è¯¯ä½†ç»§ç»­å¤„ç†å…¶ä»–å—
            logging.debug(f"è·³è¿‡æ— æ³•è§£æçš„å—: {lines}, é”™è¯¯: {e}")
            continue
    return segments, 'ã€‚'.join(full_text_parts)

def time_str_to_seconds(time_str: str) -> float:
    h, m, s_ms = time_str.replace(',', ':').split(':')
    return int(h) * 3600 + int(m) * 60 + float(s_ms)

# ==================== LLM æ¥å£ ====================
def create_llm_caller(model_name: str, base_url: Optional[str] = None) -> Callable[[str], str]:
    if model_name.startswith("gpt-"):
        try:
            from openai import OpenAI
            client = OpenAI()
        except ImportError:
            raise ImportError("è¯·å®‰è£… openai: pip install openai")
        
        def call_openai(prompt: str) -> str:
            resp = client.chat.completions.create(
                model=model_name,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3,
                max_tokens=256
            )
            return resp.choices[0].message.content.strip()
        return call_openai

    elif model_name.startswith("qwen"):
        # ä½¿ç”¨OpenAIå…¼å®¹æ–¹å¼è°ƒç”¨Qwenæ¨¡å‹
        try:
            from openai import OpenAI
        except ImportError:
            raise ImportError("è¯·å®‰è£… openai: pip install openai")
            
        # Qwenæ¨¡å‹ä½¿ç”¨DashScopeçš„OpenAIå…¼å®¹æ¥å£
        client = OpenAI(
            api_key=os.environ.get("DASHSCOPE_API_KEY", ""),
            base_url=os.environ.get("DASHSCOPE_BASE_HTTP_API_URL","https://dashscope.aliyuncs.com/compatible-mode/v1"),
        )
        
        def call_qwen(prompt: str) -> str:
            resp = client.chat.completions.create(
                model=model_name,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3,
                max_tokens=256
            )
            return resp.choices[0].message.content.strip()
        return call_qwen

    elif base_url or model_name in ["llama3", "phi3", "mistral"]:
        url = (base_url or "http://localhost:11434") + "/api/generate"
        def call_ollama(prompt: str) -> str:
            resp = requests.post(
                url,
                json={
                    "model": model_name,
                    "prompt": prompt,
                    "stream": False,
                    "options": {"temperature": 0.3, "num_predict": 256}
                },
                timeout=60
            )
            resp.raise_for_status()
            return resp.json()["response"].strip()
        return call_ollama

    else:
        # è‡ªå»º APIï¼šå‡è®¾ POST /v1/completions è¿”å› {"text": "..."}
        def call_custom(prompt: str) -> str:
            resp = requests.post(
                f"{base_url}/v1/completions",
                json={"prompt": prompt, "max_tokens": 256},
                timeout=60
            )
            resp.raise_for_status()
            return resp.json()["text"].strip()
        return call_custom

# ==================== å…³é”®è¯ä¸é’©å­æå– ====================
def extract_keywords_with_llm(srt_text: str, llm_func: Callable[[str], str]) -> List[str]:
    prompt = f"""
ä½ æ˜¯ä¸€ä¸ªçŸ­è§†é¢‘çˆ†æ¬¾å†…å®¹åˆ†æå¸ˆã€‚è¯·ä»ä»¥ä¸‹çŸ­å‰§å°è¯ä¸­ï¼Œè‡ªåŠ¨è¯†åˆ«å‡ºæœ€èƒ½å¼•å‘è§‚ä¼—æƒ…ç»ªï¼ˆå¦‚æ„¤æ€’ã€å¿ƒç–¼ã€éœ‡æƒŠã€å¥½å¥‡ï¼‰çš„ **é«˜èƒ½å…³é”®è¯æˆ–çŸ­è¯­**ï¼ˆ3â€“8ä¸ªï¼‰ã€‚
è¦æ±‚ï¼š
- å¿…é¡»æ˜¯å°è¯ä¸­å®é™…å‡ºç°çš„è¯æˆ–çŸ­å¥
- ä¼˜å…ˆé€‰æ‹©åŒ…å«å†²çªã€åè½¬ã€ç»ç—‡ã€èƒŒå›ã€æ€€å­•ã€æ›¿èº«ã€æ­»äº¡ã€ä¸´ç»ˆã€æ‰“è„¸ç­‰å…ƒç´ çš„è¯
- æ¯ä¸ªå…³é”®è¯ä¸è¶…è¿‡6ä¸ªæ±‰å­—
- è¿”å›çº¯ JSON åˆ—è¡¨ï¼Œä¸è¦ä»»ä½•è§£é‡Š

å°è¯å†…å®¹ï¼š
{srt_text}
"""
    try:
        response = llm_func(prompt)
        print(f"LLM extract_keywords_with_llmï¼š{response}")
        
        # å°è¯•ç›´æ¥è§£æå“åº”
        try:
            keywords = json.loads(response)
        except json.JSONDecodeError:
            # å¦‚æœç›´æ¥è§£æå¤±è´¥ï¼Œå°è¯•æå–ä»£ç å—ä¸­çš„JSON
            import re
            json_match = re.search(r'```(?:json)?\s*([^\]]*\])', response)
            if json_match:
                json_text = json_match.group(1)
                keywords = json.loads(json_text)
            else:
                # å¦‚æœä»ç„¶å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨å…³é”®è¯
                logging.warning(f"æ— æ³•è§£æLLMå“åº”ä¸ºJSON: {response}")
                return FALLBACK_KEYWORDS
                
        if isinstance(keywords, list) and all(isinstance(k, str) for k in keywords):
            return [k.strip() for k in keywords if k.strip()]
    except Exception as e:
        logging.warning(f"LLM å…³é”®è¯æå–å¤±è´¥: {e}")
    return FALLBACK_KEYWORDS

def select_hook_with_llm(clips: List[tuple], srt_text: str, llm_func: Callable[[str], str]) -> Optional[tuple]:
    if not clips:
        return None
    candidates = "\n".join([f"{i+1}. {text}" for i, (_, _, text,_) in enumerate(clips[:5])])
    prompt = f"""
    ä½ æ˜¯ä¸€ä½æ‹¥æœ‰åƒä¸‡ç²‰ä¸çš„æŠ–éŸ³çŸ­å‰§å¯¼æ¼”ï¼Œä¸“ç²¾äºâ€œ10ç§’é’©å­â€è®¾è®¡ã€‚
    è¯·ä»ä»¥ä¸‹å€™é€‰å°è¯ä¸­ï¼Œé€‰å‡º**å”¯ä¸€ä¸€å¥**æœ€èƒ½è®©äºº**ç«‹åˆ»åœæ­¢æ»‘åŠ¨**çš„å°è¯ä½œä¸ºè§†é¢‘å¼€å¤´ã€‚

    ã€é€‰æ‹©åŸåˆ™ã€‘ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰ï¼š
    1. **æƒ…ç»ªå†²å‡»æœ€å¼º**ï¼šåŒ…å«æåº¦æ„¤æ€’ã€éœ‡æƒŠã€å¿ƒç¢ã€ææƒ§ã€ç»æœ›æˆ–ç‹‚å–œ
    2. **å­˜åœ¨å¼ºçƒˆåè½¬æˆ–æ‚¬å¿µ**ï¼šå¦‚èº«ä»½æ­éœ²ï¼ˆâ€œä½ ä¸æ˜¯æˆ‘äº²ç”Ÿçš„ï¼â€ï¼‰ã€ç§˜å¯†æ›å…‰ï¼ˆâ€œå­©å­ä¸æ˜¯ä½ çš„ï¼â€ï¼‰ã€å‘½è¿çªå˜ï¼ˆâ€œä½ ä¸­å¥–äº†ï¼Œä½†è¦åç‰¢ï¼â€ï¼‰
    3. **å°è¯ç®€çŸ­æœ‰åŠ›**ï¼šä¼˜å…ˆé€‰æ‹© â‰¤15 ä¸ªæ±‰å­— çš„å¥å­ï¼ˆè¶ŠçŸ­è¶Šæœ‰å†²å‡»åŠ›ï¼‰
    4. **åŒ…å«å…·ä½“å†²çªåŠ¨ä½œæˆ–ç»“æœ**ï¼šå¦‚â€œä¸‹è·ªâ€ã€â€œæ‰“è„¸â€ã€â€œç¦»å©šâ€ã€â€œæŠ¥è­¦â€ã€â€œè·³æ¥¼â€ã€â€œè½¬è´¦ä¸€äº¿â€ï¼Œè€ŒéæŠ½è±¡æŠ’æƒ…
    5. **ç¦æ­¢ä½¿ç”¨ä»¥ä¸‹ç±»å‹**ï¼š  
    - ç¤¼è²Œç”¨è¯­ã€æœåŠ¡æ€§è¯­è¨€ï¼ˆå¦‚â€œæ‚¨çš„è¯â€â€œè¯·å–èŒ¶â€ï¼‰  
    - æ— ä¸»è¯­/æ— ä¸Šä¸‹æ–‡çš„ç¥ˆä½¿å¥ï¼ˆå¦‚â€œåˆ«èµ°â€â€œç­‰ç­‰â€ï¼‰  
    - é•¿åº¦è¶…è¿‡ 20 å­—çš„å¥å­

    ã€å€™é€‰å°è¯ã€‘ï¼š
    {candidates}

    ã€è¾“å‡ºè¦æ±‚ã€‘ï¼š
    - ä»…è¿”å›é€‰ä¸­çš„å°è¯åŸæ–‡ï¼ˆé€å­—ï¼Œä¸åŠ å¼•å·ã€ç¼–å·æˆ–æ ‡ç‚¹ä¿®æ­£ï¼‰
    - ä¸è¦ä»»ä½•è§£é‡Šã€æ¢è¡Œæˆ–é¢å¤–å­—ç¬¦
    - è‹¥æ‰€æœ‰å°è¯éƒ½å¹³æ·¡ï¼Œé€‰æ‹©æƒ…ç»ªæœ€æµ“çƒˆçš„ä¸€å¥
    """
    try:
        hook_text = llm_func(prompt).strip().strip('"').strip("'")
        # æ¸…ç†å¯èƒ½çš„ä»£ç å—æ ‡è®°
        if hook_text.startswith("```") and hook_text.endswith("```"):
            hook_text = hook_text[3:-3].strip()
            
        for start, end, text,kw in clips:
            if hook_text in text or text.replace(" ", "") in hook_text.replace(" ", ""):
                return (start, end, text, kw)
        return (clips[0][0], clips[0][1], clips[0][2], "")
    except Exception as e:
        logging.warning(f"LLM é’©å­é€‰æ‹©å¤±è´¥: {e}")
        return (clips[0][0], clips[0][1], clips[0][2], "")

# ==================== è§†é¢‘å‰ªè¾‘æ ¸å¿ƒ ====================
def find_clips_by_keywords(segments: list, keywords: List[str], expand_sec: float = 1.0) -> List[tuple]:
    keyword_set = set(kw for kw in keywords if kw)
    clips = []
    for seg in segments:
        text = seg['text']
        for kw in keyword_set:
            if kw in text:
                start = max(0, seg['start'] - expand_sec)
                end = seg['end'] + expand_sec
                clips.append((start, end, text, kw))
                break
    return clips


def insert_images_into_video(video_clips: List, subtitle_items: List, clip_srt: str, 
                           image_paths_and_times: List[tuple], video_size: tuple, fps: float) -> tuple:
    """
    åœ¨è§†é¢‘çš„æŒ‡å®šæ—¶é—´ç‚¹æ’å…¥å›¾ç‰‡
    
    Args:
        video_clips: å·²æœ‰çš„è§†é¢‘ç‰‡æ®µåˆ—è¡¨
        subtitle_items: å·²æœ‰çš„å­—å¹•é¡¹åˆ—è¡¨
        clip_srt: å·²æœ‰çš„SRTå­—å¹•å†…å®¹
        image_paths_and_times: å›¾ç‰‡è·¯å¾„å’Œæ’å…¥æ—¶é—´çš„å…ƒç»„åˆ—è¡¨ [(path, start_time, duration), ...]
        video_size: è§†é¢‘å°ºå¯¸ (width, height)
        fps: è§†é¢‘å¸§ç‡
    
    Returns:
        tuple: (updated_video_clips, updated_subtitle_items, updated_clip_srt, updated_current_time)
    """
    if not image_paths_and_times:
        # å¦‚æœæ²¡æœ‰å›¾ç‰‡éœ€è¦æ’å…¥ï¼Œç›´æ¥è¿”å›åŸå§‹æ•°æ®
        # è®¡ç®—å½“å‰æ€»æ—¶é•¿
        current_time = sum([clip.duration for clip in video_clips])
        return video_clips, subtitle_items, clip_srt, current_time
    
    try:
        from moviepy.editor import ImageClip
    except ImportError:
        logging.warning("moviepy.editor.ImageClip æ— æ³•å¯¼å…¥ï¼Œå›¾ç‰‡æ’å…¥åŠŸèƒ½ä¸å¯ç”¨")
        # è®¡ç®—å½“å‰æ€»æ—¶é•¿
        current_time = sum([clip.duration for clip in video_clips])
        return video_clips, subtitle_items, clip_srt, current_time
    
    # æŒ‰æ—¶é—´æ’åºå›¾ç‰‡æ’å…¥ç‚¹
    sorted_images = sorted(image_paths_and_times, key=lambda x: x[1])  # æŒ‰å¼€å§‹æ—¶é—´æ’åº
    
    # åˆå§‹åŒ–ç»“æœåˆ—è¡¨
    result_video_clips = []
    result_subtitle_items = subtitle_items[:]  # å¤åˆ¶åŸå§‹å­—å¹•é¡¹
    result_clip_srt = clip_srt
    current_time = 0.0
    
    # å½“å‰å¤„ç†çš„è§†é¢‘ç‰‡æ®µç´¢å¼•
    clip_index = 0
    total_video_duration = sum([clip.duration for clip in video_clips])
    
    # å¤„ç†æ¯ä¸ªå›¾ç‰‡æ’å…¥ç‚¹
    for img_path, img_start_time, img_duration in sorted_images:
        # ç¡®ä¿å›¾ç‰‡æ’å…¥æ—¶é—´åœ¨åˆç†èŒƒå›´å†…
        img_start_time = max(0, min(img_start_time, total_video_duration))
        
        # æ·»åŠ åœ¨å›¾ç‰‡ä¹‹å‰çš„æ‰€æœ‰è§†é¢‘ç‰‡æ®µ
        while clip_index < len(video_clips):
            clip = video_clips[clip_index]
            clip_end_time = current_time + clip.duration
            
            # å¦‚æœå½“å‰ç‰‡æ®µç»“æŸæ—¶é—´åœ¨å›¾ç‰‡æ’å…¥æ—¶é—´ä¹‹å‰ï¼Œåˆ™å®Œæ•´æ·»åŠ è¯¥ç‰‡æ®µ
            if clip_end_time <= img_start_time:
                result_video_clips.append(clip)
                current_time = clip_end_time
                clip_index += 1
            else:
                # éœ€è¦åœ¨å½“å‰ç‰‡æ®µä¸­æ’å…¥å›¾ç‰‡
                # è®¡ç®—åœ¨å½“å‰ç‰‡æ®µä¸­æ’å…¥ç‚¹çš„ç›¸å¯¹ä½ç½®
                relative_insert_time = img_start_time - current_time
                
                if relative_insert_time > 0:
                    # åœ¨æ’å…¥ç‚¹ä¹‹å‰åˆ†å‰²ç‰‡æ®µ
                    before_clip = video_clips[clip_index].subclip(0, relative_insert_time)
                    result_video_clips.append(before_clip)
                    current_time += before_clip.duration
                    
                    # æ›´æ–°å‰©ä½™ç‰‡æ®µä¾›åç»­å¤„ç†
                    remaining_clip = video_clips[clip_index].subclip(relative_insert_time)
                    video_clips[clip_index] = remaining_clip
                break
        
        # æ’å…¥å›¾ç‰‡ç‰‡æ®µ
        try:
            if os.path.exists(img_path):
                def _make_image_clip(path: str, duration: float, size: tuple, fps: float):
                    p = os.path.normpath(str(path)).strip()
                    try:
                        from PIL import Image
                        img = Image.open(p).convert("RGB")
                        w, h = size
                        try:
                            resample = Image.Resampling.LANCZOS
                        except AttributeError:
                            resample = Image.LANCZOS
                        img = img.resize((w, h), resample=resample)
                        import numpy as np
                        arr = np.array(img)
                        from moviepy.editor import ImageClip
                        return ImageClip(arr, duration=duration).set_fps(fps)
                    except Exception:
                        try:
                            import numpy as np
                            import cv2
                            data = np.fromfile(p, dtype=np.uint8)
                            img = cv2.imdecode(data, cv2.IMREAD_COLOR)
                            if img is None:
                                return None
                            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                            w, h = size
                            img = cv2.resize(img, (w, h), interpolation=cv2.INTER_AREA)
                            from moviepy.editor import ImageClip
                            return ImageClip(img, duration=duration).set_fps(fps)
                        except Exception:
                            return None

                image_clip = _make_image_clip(img_path, img_duration, video_size, fps)
                if image_clip:
                    result_video_clips.append(image_clip)
                    hours_start = int(current_time // 3600)
                    minutes_start = int((current_time % 3600) // 60)
                    seconds_start = int(current_time % 60)
                    milliseconds_start = int((current_time % 1) * 1000)
                    hours_end = int((current_time + img_duration) // 3600)
                    minutes_end = int(((current_time + img_duration) % 3600) // 60)
                    seconds_end = int((current_time + img_duration) % 60)
                    milliseconds_end = int(((current_time + img_duration) % 1) * 1000)
                    start_time_str = f"{hours_start:02d}:{minutes_start:02d}:{seconds_start:02d},{milliseconds_start:03d}"
                    end_time_str = f"{hours_end:02d}:{minutes_end:02d}:{seconds_end:02d},{milliseconds_end:03d}"
                    next_index = len(result_subtitle_items) + 1
                    result_subtitle_items.append(((current_time, current_time + img_duration), "[å›¾ç‰‡]"))
                    result_clip_srt += f"{next_index}\n{start_time_str} --> {end_time_str}\n[å›¾ç‰‡]\n\n"
                    current_time += img_duration
                else:
                    logging.warning(f"æ— æ³•åŠ è½½å›¾ç‰‡ {img_path}")
            else:
                logging.warning(f"å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {img_path}")
        except Exception as e:
            logging.warning(f"æ— æ³•åŠ è½½å›¾ç‰‡ {img_path}: {e}")
    
    # æ·»åŠ å‰©ä½™çš„æ‰€æœ‰è§†é¢‘ç‰‡æ®µ
    while clip_index < len(video_clips):
        result_video_clips.append(video_clips[clip_index])
        clip_index += 1
    
    return result_video_clips, result_subtitle_items, result_clip_srt, current_time


def create_promo_video(
    video_path: str,
    srt_content: str,
    output_path: Optional[str] = None,
    llm_model: str = "qwen-plus",
    llm_base_url: Optional[str] = None,
    bgm_path: Optional[str] = None,
    font_path: str = './font/STHeitiMedium.ttc',
    font_size: int = 28,
    expand_sec: float = 10.0,
    max_clips: int = 5,
    cover_image_path: Optional[str] = None,
    image_inserts: Optional[List[tuple]] = None  # [(image_path, time, duration), ...]
):
    if not MOVIEPY_AVAILABLE:
        raise RuntimeError("moviepy æœªå®‰è£…ï¼Œæ— æ³•ç”Ÿæˆè§†é¢‘ã€‚è¯·è¿è¡Œ: pip install moviepy")
    
    # å¦‚æœæœªæä¾› output_pathï¼Œåˆ™æ ¹æ® video_path è‡ªåŠ¨ç”Ÿæˆ
    if output_path is None or len(output_path) == 0:
        # è·å–è§†é¢‘æ–‡ä»¶çš„ç›®å½•å’ŒåŸºæœ¬åç§°
        video_dir = os.path.dirname(video_path)
        video_name = os.path.basename(video_path)
        # ç§»é™¤æ‰©å±•åå¹¶æ·»åŠ  _output.mp4 åç¼€
        base_name, _ = os.path.splitext(video_name)
        output_path = os.path.join(video_dir, f"{base_name}_output.mp4")
        
    # 1. è§£æ SRT
    # ä¿®æ”¹ä¸ºåŒæ—¶æ”¯æŒæ–‡ä»¶è·¯å¾„å’ŒSRTå†…å®¹å­—ç¬¦ä¸²
    if srt_content.endswith('.srt') and os.path.isfile(srt_content):
        segments, srt_text = srt_to_segments(srt_content)
    else:
        # ç›´æ¥è§£æSRTå†…å®¹å­—ç¬¦ä¸²
        srt_content_str = srt_content  # è¿™é‡Œå®é™…ä¸Šæ˜¯SRTå†…å®¹è€Œéè·¯å¾„
        print(f"è§£æç›´æ¥æä¾›çš„ SRT å†…å®¹å­—ç¬¦ä¸²={srt_content_str}")
        # å¤„ç†ä¸åŒæ“ä½œç³»ç»Ÿçš„æ¢è¡Œç¬¦
        srt_content_str = srt_content_str.replace('\r\n', '\n').replace('\r', '\n')
        blocks = re.split(r'\n\s*\n', srt_content_str.strip())
        segments = []
        full_text_parts = []
        for block in blocks:
            lines = [line.strip() for line in block.split('\n') if line.strip()]
            # è‡³å°‘éœ€è¦2è¡Œï¼ˆåºå·è¡Œå’Œæ—¶é—´è½´è¡Œï¼‰ï¼Œæ–‡æœ¬å¯ä»¥ä¸ºç©º
            if len(lines) < 2:
                continue

            try:
                # æ–‡æœ¬ä»ç¬¬3è¡Œå¼€å§‹ï¼Œå¦‚æœæ²¡æœ‰æ–‡æœ¬åˆ™ä¸ºç©ºå­—ç¬¦ä¸²
                text = ' '.join(lines[2:]) if len(lines) > 2 else ""
                full_text_parts.append(text)

                # è§£ææ—¶é—´è½´
                time_line = lines[1]
                start_str, end_str = time_line.split(' --> ')

                # å®šä¹‰æ—¶é—´å­—ç¬¦ä¸²åˆ°ç§’çš„è½¬æ¢å‡½æ•°
                def time_str_to_seconds(time_str):
                    h, m, s = time_str.split(':')
                    s, ms = s.split(',')
                    return int(h) * 3600 + int(m) * 60 + int(s) + int(ms) / 1000

                start_sec = time_str_to_seconds(start_str)
                end_sec = time_str_to_seconds(end_str)

                segments.append({'start': start_sec, 'end': end_sec, 'text': text})

            except Exception as e:
                # è®°å½•é”™è¯¯ä½†ç»§ç»­å¤„ç†å…¶ä»–å—
                print(f"è·³è¿‡æ— æ³•è§£æçš„å—: {lines}, é”™è¯¯: {e}")
                continue
        srt_text = 'ã€‚'.join(full_text_parts)
        
    if not segments:
        raise ValueError("SRT æ–‡ä»¶ä¸ºç©ºæˆ–æ ¼å¼é”™è¯¯")
    logging.info(f"âœ… è§£æ {len(segments)} æ¡å­—å¹•")

    # 2. åˆå§‹åŒ– LLM
    llm_func = create_llm_caller(llm_model, llm_base_url)
    logging.info(f"ğŸ§  ä½¿ç”¨ LLM: {llm_model}")

    # 3. åŠ¨æ€æå–å…³é”®è¯
    keywords = extract_keywords_with_llm(srt_text, llm_func)
    print(f"ğŸ”‘ é«˜èƒ½å…³é”®è¯: {keywords}")

    # 4. æå–é«˜èƒ½ç‰‡æ®µ
    all_clips = find_clips_by_keywords(segments, keywords, expand_sec=expand_sec)
    if not all_clips:
        raise ValueError("æœªæ‰¾åˆ°åŒ¹é…å…³é”®è¯çš„ç‰‡æ®µ")

    # 5. é€‰æ‹©é»„é‡‘3ç§’é’©å­
    hook_clip = select_hook_with_llm(all_clips, srt_text, llm_func)
    print(f"ğŸ£ é»„é‡‘3ç§’: {hook_clip[2] if hook_clip else 'N/A'}")

    # 6. æ„å»ºå‰ªè¾‘åˆ—è¡¨ï¼ˆé’©å­ + å…¶ä»–ï¼‰
    video_clips = []
    subtitle_items = []
    current_time = 0.0

    # åŠ è½½ä¸»è§†é¢‘
    video = VideoFileClip(video_path)
    total_clips = [hook_clip] if hook_clip else []
    used_texts = {hook_clip[2]} if hook_clip else set()

    for clip in all_clips:
        if clip[2] not in used_texts and len(total_clips) < max_clips:
            total_clips.append(clip)
            used_texts.add(clip[2])

    # 7. é€ç‰‡æ®µå¤„ç†
    clip_srt = ""  # æ”¶é›†æ‰€æœ‰ç‰‡æ®µçš„SRTå†…å®¹
    current_time = 0.0  # é‡ç½®å½“å‰æ—¶é—´ï¼Œå¦‚æœæ·»åŠ å°é¢éœ€è¦é¢å¤–æ—¶é—´
    
    # å¦‚æœæä¾›äº†å°é¢å›¾ç‰‡ï¼Œåˆ™åˆ›å»ºå°é¢ç‰‡æ®µ
    cover_clip = None
    if cover_image_path and os.path.exists(cover_image_path):
        try:
            def _make_image_clip(path: str, duration: float, size: tuple, fps: float):
                p = os.path.normpath(str(path)).strip()
                try:
                    from PIL import Image
                    img = Image.open(p).convert("RGB")
                    w, h = size
                    try:
                        resample = Image.Resampling.LANCZOS
                    except AttributeError:
                        resample = Image.LANCZOS
                    img = img.resize((w, h), resample=resample)
                    import numpy as np
                    arr = np.array(img)
                    from moviepy.editor import ImageClip
                    return ImageClip(arr, duration=duration).set_fps(fps)
                except Exception:
                    try:
                        import numpy as np
                        import cv2
                        data = np.fromfile(p, dtype=np.uint8)
                        img = cv2.imdecode(data, cv2.IMREAD_COLOR)
                        if img is None:
                            return None
                        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                        w, h = size
                        img = cv2.resize(img, (w, h), interpolation=cv2.INTER_AREA)
                        from moviepy.editor import ImageClip
                        return ImageClip(img, duration=duration).set_fps(fps)
                    except Exception:
                        return None
            cover_clip = _make_image_clip(cover_image_path, 2.0, video.size, video.fps)
            if cover_clip is not None:
                current_time += 2.0
        except Exception as e:
            logging.warning(f"æ— æ³•åŠ è½½å°é¢å›¾ç‰‡: {e}")
            cover_clip = None
    if cover_clip is None:
        try:
            from moviepy.editor import ImageClip
            frame = video.get_frame(0)
            cover_clip = ImageClip(frame, duration=2.0).set_fps(video.fps)
            current_time += 2.0
        except Exception:
            cover_clip = None

    # å¤„ç†ä¸»è¦è§†é¢‘ç‰‡æ®µ
    video_clips = []
    subtitle_items = []
    
    # å¦‚æœæœ‰å°é¢å‰ªè¾‘ï¼Œåˆ™æ·»åŠ åˆ°è§†é¢‘ç‰‡æ®µåˆ—è¡¨å¼€å¤´
    if cover_clip is not None:
        video_clips.append(cover_clip)
        
        # æ·»åŠ ä¸€ä¸ªç©ºå­—å¹•æ¡ç›®ç»™å°é¢ï¼ˆæ²¡æœ‰å­—å¹•ï¼‰
        # æ³¨æ„ï¼šå°é¢ä¸æ·»åŠ å­—å¹•ï¼Œæ‰€ä»¥ä¸æ›´æ–°subtitle_items
        
        # å°é¢çš„SRTæ¡ç›®
        start_time_str = "00:00:00,000"
        end_time_str = "00:00:02,000"
        clip_srt += f"1\n{start_time_str} --> {end_time_str}\n[å°é¢]\n\n"

    print(f"æ€»ç‰‡æ®µ: {total_clips}")    
    for i, (start, end, text, kw) in enumerate(total_clips):
        start = max(0, start)
        end = min(video.duration, end)
        if end <= start:
            continue
        clip_vid = video.subclip(start, end)
        video_clips.append(clip_vid)
        
        # å­—å¹•ç´¢å¼•éœ€è¦è€ƒè™‘å°é¢ï¼ˆå¦‚æœæœ‰ï¼‰
        subtitle_index = i + (2 if cover_clip is not None else 1)
        subtitle_items.append(((current_time, current_time + (end - start)), kw))
        
        # åˆ›å»ºSRTæ¡ç›®
        hours_start = int(current_time // 3600)
        minutes_start = int((current_time % 3600) // 60)
        seconds_start = int(current_time % 60)
        milliseconds_start = int((current_time % 1) * 1000)
        
        hours_end = int((current_time + (end - start)) // 3600)
        minutes_end = int(((current_time + (end - start)) % 3600) // 60)
        seconds_end = int((current_time + (end - start)) % 60)
        milliseconds_end = int(((current_time + (end - start)) % 1) * 1000)
        
        start_time_str = f"{hours_start:02d}:{minutes_start:02d}:{seconds_start:02d},{milliseconds_start:03d}"
        end_time_str = f"{hours_end:02d}:{minutes_end:02d}:{seconds_end:02d},{milliseconds_end:03d}"
        
        clip_srt += f"{subtitle_index}\n{start_time_str} --> {end_time_str}\n{text}\n\n"
        
        current_time += (end - start)

    if not video_clips:
        raise ValueError("æ— å¯å‰ªè¾‘ç‰‡æ®µ")

    # å¦‚æœæä¾›äº†ä¸­é—´æ’å…¥çš„å›¾ç‰‡ï¼Œåˆ™å¤„ç†è¿™äº›å›¾ç‰‡
    if image_inserts:
        video_clips, subtitle_items, clip_srt, current_time = insert_images_into_video(
            video_clips, subtitle_items, clip_srt, image_inserts, video.size, video.fps
        )

    # 8. åˆå¹¶è§†é¢‘
    final_video = concatenate_videoclips(video_clips) if len(video_clips) > 1 else video_clips[0]

    # 9. æ·»åŠ å­—å¹•
    def make_textclip(txt):
        return TextClip(
            txt,
            font=font_path,
            fontsize=font_size,
            color='white',
            stroke_color='white',
            stroke_width=2,
            size=final_video.size,
            method='caption',
            align='south'
        )
    
    if subtitle_items:
        subtitles = SubtitlesClip(subtitle_items, make_textclip)
        final_video = CompositeVideoClip([final_video, subtitles.set_pos(('center', 'bottom'))])

    # 10. å åŠ  BGM
    if bgm_path and os.path.exists(bgm_path):
        bgm = AudioFileClip(bgm_path)
        if bgm.duration < final_video.duration:
            bgm = afx.audio_loop(bgm, duration=final_video.duration)
        else:
            bgm = bgm.subclip(0, final_video.duration)
        bgm = bgm.fx(afx.audio_fadein, 1.0).fx(afx.audio_fadeout, 1.0)
        
        original_audio = final_video.audio
        if original_audio:
            final_audio = original_audio.volumex(0.6).fx(afx.composite, bgm.volumex(0.4))
        else:
            final_audio = bgm.volumex(0.5)
        final_video = final_video.set_audio(final_audio)

    # 11. å¯¼å‡º
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    final_video.write_videofile(
        output_path,
        codec='libx264',
        audio_codec='aac',
        temp_audiofile=output_path.replace('.mp4', '_temp.m4a'),
        remove_temp=True,
        logger='bar',
        threads=min(8, os.cpu_count() or 4), # å¯ç”¨å¤šçº¿ç¨‹å†™å…¥
        ffmpeg_params=[
            '-preset', 'ultrafast',     # âš¡ æœ€å¿«ç¼–ç é€Ÿåº¦ï¼ˆç‰ºç‰²å‹ç¼©ç‡ï¼‰
            '-tune', 'fastdecode',      # ä¼˜åŒ–è§£ç é€Ÿåº¦ï¼ˆå¯é€‰ï¼‰
            '-threads', '0',            # è‡ªåŠ¨ä½¿ç”¨æ‰€æœ‰ CPU æ ¸å¿ƒï¼ˆç­‰ä»·äº -threads autoï¼‰
            '-x264-params', 'nal-hrd=cbr',  # é¿å…å˜ç ç‡æ³¢åŠ¨ï¼ˆå¯é€‰ï¼‰
        ]
    )
    logging.info(f"âœ… æ¨å¹¿è§†é¢‘å·²ç”Ÿæˆ: {output_path}")
    
    # è¿”å›ä¸ç°æœ‰æ¥å£å…¼å®¹çš„è¾“å‡ºæ ¼å¼
    message = f"æˆåŠŸç”Ÿæˆæ¨å¹¿è§†é¢‘ï¼ŒåŒ…å« {len(total_clips)} ä¸ªç‰‡æ®µ"
    return output_path, None, message, clip_srt

# ==================== CLI ====================
def main():
    parser = argparse.ArgumentParser(description="AI çŸ­å‰§æ¨å¹¿è§†é¢‘è‡ªåŠ¨å‰ªè¾‘ï¼ˆLLM åŠ¨æ€ç”Ÿæˆé«˜èƒ½å…³é”®è¯ï¼‰")
    parser.add_argument("--video",default="D:\\pythonwork\\FunClip\\data\\merged_video_ae02936d.mp4", help="åŸå§‹è§†é¢‘è·¯å¾„")
    parser.add_argument("--srt", default="D:\\pythonwork\\FunClip\\data\\srt.srt", help="SRT å­—å¹•æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--output", default="D:\\pythonwork\\FunClip\\data\\output\\merged_video_ae02936d.mp4", help="è¾“å‡ºè§†é¢‘è·¯å¾„")
    parser.add_argument("--llm", default="qwen3-max", help="LLM æ¨¡å‹åï¼ˆå¦‚ qwen, llama3, gpt-4oï¼‰")
    parser.add_argument("--llm_url", default=None, help="LLM API åœ°å€ï¼ˆå¦‚ http://localhost:11434ï¼‰")
    parser.add_argument("--bgm", default=None, help="èƒŒæ™¯éŸ³ä¹è·¯å¾„ï¼ˆå¯é€‰ï¼‰")
    parser.add_argument("--font", default="./font/STHeitiMedium.ttc", help="ä¸­æ–‡å­—ä½“è·¯å¾„")
    parser.add_argument("--max_clips", type=int, default=5, help="æœ€å¤§ç‰‡æ®µæ•°é‡ï¼ˆå«é’©å­ï¼‰")
    parser.add_argument("--expand", type=float, default=1.0, help="ç‰‡æ®µå‰åæ‰©å±•ç§’æ•°")

    args = parser.parse_args()
   
    create_promo_video(
        video_path=args.video,
        srt_content=args.srt,
        output_path=args.output,
        llm_model=args.llm,
        llm_base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
        bgm_path=args.bgm,
        font_path=args.font,
        expand_sec=args.expand,
        max_clips=args.max_clips
    )

if __name__ == "__main__":
    main()
